{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Jenyl Murdock\n",
    "* Student pace: part time \n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Joe San Pietro\n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here - remember to use markdown cells for comments as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the data file and get a visual of the information\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for multicollinearity\n",
    "import seaborn as sns\n",
    "\n",
    "# look at results for each linear regression model using statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "kc = pd.read_csv('kc_house_data.csv')\n",
    "print (kc.shape)\n",
    "kc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert description of column names, grade, & condition here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For bathrooms:\n",
    "Values are decimal and calculated as:\n",
    "Full bathrooms (ensuite) = 1\n",
    "Half bathrooms (separate )= 0.5\n",
    "Powder rooms (only toilet and sink) = 0.25\n",
    "(Dahlin, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see how each column is categorized\n",
    "kc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II.  Scrub the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The id column is not needed so it can be dropped from the data\n",
    "kc = kc.drop(['id'], axis=1)\n",
    "kc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with an initial data type conversion\n",
    "# For columns that are obviouly categorized wrong, convert them to an appropriate data type\n",
    "kc['date'] = pd.to_datetime(kc.date)\n",
    "kc['condition'] = kc.condition.astype(int)\n",
    "kc['grade'] = kc.grade.astype(int)\n",
    "\n",
    "kc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.  Remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in the dataset \n",
    "kc.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View has 63 null values.  Because this is not a significant number, these can be dropped from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (kc.view.unique())\n",
    "print (kc.view.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the data for where the view is not a nan value\n",
    "# convert view to data type string so the 'nan' data can be dropped\n",
    "kc['view'] = kc.view.astype(str)\n",
    "kc = kc[kc.view != 'nan']  \n",
    "kc['view'] = kc.view.astype(float)\n",
    "kc['view'] = kc.view.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null values with 0 in waterfront column and change to data type integer\n",
    "kc.waterfront = kc.waterfront.fillna(value=0)\n",
    "kc.waterfront = kc.waterfront.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null values in yr_renovated with 0 and change to data type integer\n",
    "kc.yr_renovated = kc.yr_renovated.fillna(value=0)\n",
    "kc.yr_renovated = kc.yr_renovated.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that there are not any more null values\n",
    "kc.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.  reformat some columns and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the year built to reflect the age of the house. This format will be easier to visualize\n",
    "# https://github.com/matthewsparr/King-County-Sales-Analysis/blob/master/student2.ipynb\n",
    "kc['yr_built'].describe()\n",
    "kc['age'] = (kc.yr_built.max() - kc.yr_built + 1)\n",
    "kc = kc.drop(['yr_built'], axis=1)\n",
    "kc.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bedrooms data contains one significant outlier of 33 which could very well be a data entry error.\n",
    "There are 38 houses with 7 bedrooms, 13 houses with 8 bedrooms, 6 with 9 bedrooms, 3 with 10, 1 with 11\n",
    "Example code used for this information:  (kc.bedrooms == 9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the values from 1-6 bedrooms\n",
    "print (kc.bedrooms.value_counts())\n",
    "kc = kc[kc['bedrooms'] < 7]\n",
    "kc.bedrooms.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns for unusable data by looking at the unique values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc.floors.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc.bathrooms.unique()\n",
    "kc.condition.unique()\n",
    "kc.grade.unique()\n",
    "kc.sqft_living.unique() \n",
    "kc.sqft_lot.unique()\n",
    "kc.condition.unique()\n",
    "kc.grade.unique()\n",
    "kc.sqft_above.unique()\n",
    "kc.sqft_basement.unique()  # '?' in the data\n",
    "\n",
    "(kc.sqft_basement =='?').sum()  # there are 450 '?' in this column\n",
    "#(kc.sqft_basement == '0.0').sum()  # there are 12798 '0.0' values in this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the '?' values with 0 i the sqft_basement data\n",
    "kc['sqft_basement'] = (kc['sqft_basement'].replace('?', 0)).astype(float)\n",
    "kc['sqft_basement'] = kc['sqft_basement'].astype(int)\n",
    "\n",
    "# Instead of square feet values for the basement, let's just use a categorical value of 1 for if it has a basement\n",
    "# and 0 for if it does not have a basement.\n",
    "# https://github.com/matthewsparr/King-County-Sales-Analysis/blob/master/student2.ipynb\n",
    "kc['basement'] = kc['sqft_basement'].apply(lambda row: 0 if row == 0 else 1) \n",
    "print(kc['basement'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (kc['view'].value_counts())\n",
    "\n",
    "# A significant majority of the values for the variable view are 0, let's just use a categorical value of 1 for \n",
    "# if it has a view and 0 for if it does not have a view.\n",
    "# https://github.com/matthewsparr/King-County-Sales-Analysis/blob/master/student2.ipynb\n",
    "\n",
    "kc['has_view'] = kc['view'].apply(lambda row: 1 if row != 0 else 0)\n",
    "print (kc['has_view'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all data is converted to appropriate data type\n",
    "kc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure and generate a heatmap of the data\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(kc.corr(), center = 0, linewidths = .25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like sqft_living, grade has high collinearity with some other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an initial visualization of the data\n",
    "# Note:  extra white space on either side of the graph indicates outliers which need to be removed\n",
    "kc.hist(figsize=(15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using log transformation\n",
    "#   the variables basement, age, has_view, yr_renovated cannot be log transformed due to their values of 0\n",
    "import numpy as np\n",
    "kc_log = pd.DataFrame([])\n",
    "\n",
    "kc_log['bathrooms'] = np.log(kc.bathrooms)\n",
    "kc_log['bedrooms'] = np.log(kc.bedrooms)\n",
    "kc_log['condition'] = np.log(kc.condition)\n",
    "kc_log['floors'] = np.log(kc.floors)\n",
    "kc_log['grade'] = np.log(kc.grade)\n",
    "kc_log['price'] = np.log(kc.price)\n",
    "kc_log['sqft_above'] = np.log(kc.sqft_above)\n",
    "kc_log['sqft_living'] = np.log(kc.sqft_living)\n",
    "kc_log['sqft_lot'] = np.log(kc.sqft_lot)\n",
    "kc_log['sqft_lot15'] = np.log(kc.sqft_lot15)\n",
    "kc_log['zipcode'] = np.log(kc.zipcode)\n",
    "\n",
    "# look at the histograms of the transformed data\n",
    "kc_log.hist(figsize = (15,15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to numeric format with one-hot encoding\n",
    "\n",
    "#  Change the selected categorical variables to data type'category'\n",
    "#kc.condition = kc.condition.astype('category')\n",
    "#kc.floors = kc.floors.astype('category')\n",
    "#kc.grade = kc.grade.astype('category')\n",
    "kc.has_view = kc.has_view.astype('category')\n",
    "kc.waterfront = kc.waterfront.astype('category')\n",
    "kc.basement = kc.basement.astype('category')\n",
    "\n",
    "#cond_dummies = pd.get_dummies(kc.condition, prefix = 'condition')\n",
    "#floors_dummies = pd.get_dummies(kc.floors, prefix = 'floors')\n",
    "#grade_dummies = pd.get_dummies(kc.grade, prefix = 'grade')\n",
    "has_view_dummies = pd.get_dummies(kc.has_view, prefix = 'view')\n",
    "water_dummies = pd.get_dummies(kc.waterfront, prefix = 'waterfront')\n",
    "basement_dummies = pd.get_dummies(kc.basement, prefix = 'basement')\n",
    "\n",
    "\n",
    "\n",
    "kc = kc.drop(['view', 'has_view', 'waterfront', 'sqft_basement', 'basement'], axis=1)\n",
    "kc = pd.concat([kc, has_view_dummies, water_dummies, basement_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the max_columns attribute in order to view all of the column names with the categorical data\n",
    "pd.set_option('display.max_columns', None)\n",
    "kc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an OLS regression using the log transformed data\n",
    "col_names = kc_log.columns.drop(['price'])\n",
    "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p_value']]\n",
    "\n",
    "for idx, val in enumerate(col_names):\n",
    "    print ('Kings County:  Price ~ ' + val)\n",
    "    print ('-------------------------------------')\n",
    "    \n",
    "    f = 'price~' + val\n",
    "    model = smf.ols(formula = f, data = kc_log).fit()\n",
    "    X_new = pd.DataFrame({val: [kc_log[val].min(), kc_log[val].max()]});\n",
    "    predic = model.predict(X_new)\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "    print (results[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results table to a dataframe\n",
    "print ('Regression Model with log transformed data')\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value does not give us any significant value that shows a variable should be removed.\n",
    "The three highest r-squared values are for grade, sqft_above, and sqft_living "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column indices for reference locations\n",
    "kc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an initial OLS regression between the continuous independent variables and the dependent variable\n",
    "# do not include id, date and the categorical data, so use columns 2 through 15\n",
    "col_names  = kc.columns[2:17]\n",
    "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p_value']]\n",
    "\n",
    "for idx, val in enumerate(col_names):\n",
    "    print()\n",
    "    print ('Kings County:  Price ~ ' + val)\n",
    "    print ('-------------------------------------')\n",
    "    \n",
    "    f = 'price~' + val\n",
    "    model = smf.ols(formula = f, data = kc).fit()\n",
    "    X_new = pd.DataFrame({val: [kc[val].min(), kc[val].max()]});\n",
    "    predic = model.predict(X_new)\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "    print (results[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the continuous variables results table to a dataframe\n",
    "print ()\n",
    "print ('OLS with continuous variables - 1st Iteration')\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove obvious variables such as:\n",
    "    p-value > .05\n",
    "    r squared value that are very close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this situation, longitude and latitude are not very predictive and can be eliminated.  They need each other \n",
    "# in order to have any meaning and for now, zipcode does a similar function in one variable.\n",
    "\n",
    "# The variable sqft_living has a lot of correlation as seen in the heat map.  It also has the highest r-squared\n",
    "# value of our continueous variables.\n",
    "\n",
    "drop_cols = ['lat', 'long', 'sqft_living']\n",
    "kc = kc.drop(drop_cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the first round of variables, run the OLS again on the remaining continuous variables.\n",
    "Since a few columns have been deleted, the column indices need to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column indices as some have been removed\n",
    "kc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = kc.columns[2:14]\n",
    "\n",
    "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p_value']]\n",
    "\n",
    "for idx, val in enumerate(col_names):\n",
    "    print()\n",
    "    print ('Kings County:  Price ~ ' + val)\n",
    "    print ('-------------------------------------')\n",
    "    \n",
    "    f = 'price~' + val\n",
    "    model = smf.ols(formula = f, data = kc).fit()\n",
    "    X_new = pd.DataFrame({val: [kc[val].min(), kc[val].max()]});\n",
    "    predic = model.predict(X_new)\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "    print (results[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the continuous variables results table to a dataframe\n",
    "print ()\n",
    "print ('OLS with continuous variables - 2nd Iteration')\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    In this iteration, it looks like the p_values are not a determing factor again, but the r-squared values of bathrooms, grade, sqft_above, and sqft_living15 are high compared to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns grade amd sqft_living15\n",
    "drop_cols =['grade','sqft_living15']\n",
    "kc = kc.drop(drop_cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run an initial OLS regression with the categorial data (columns 12 and on) and the dependent variable\n",
    "col_names = kc.columns[12:]  # check the column starting point\n",
    "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p_value']]\n",
    "\n",
    "for idx, val in enumerate(col_names):\n",
    "    print ('Kings County:  Price ~ ' + val)\n",
    "    print ('-------------------------------------')\n",
    "    \n",
    "    f = 'price~' + val\n",
    "    model = smf.ols(formula = f, data = kc).fit()\n",
    "    X_new = pd.DataFrame({val: [kc[val].min(), kc[val].max()]});\n",
    "    predic = model.predict(X_new)\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "    print (results[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # convert the categorical variables results table to a dataframe\n",
    "print ()\n",
    "print ('OLS with categorical variables')\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate whether any categorical variables should be eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure about which ones.  view has higher than waterfront or basement, so maybe view goes\n",
    "drop_cols = ['view_0', 'view_1']\n",
    "kc = kc.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation is consider high if its absolute value is around 0.7 - 0.8.\n",
    "Let's use 0.75 as a guide to see how many high correlations there are.\n",
    "There were no variables that have that high of correlation.  Let's try 0.7.\n",
    "This showed a high correlation between sqft_lot and sqft_lot15.  Let's go ahead and\n",
    "drop the sqft_lot15 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(kc.corr() > 0.7)\n",
    "kc = kc.drop(['sqft_lot15'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run an OLS regression with the remaining data (columns 2 and on) and the dependent variable\n",
    "col_names = kc.columns[2:]  # adjust the column starting point\n",
    "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p_value']]\n",
    "\n",
    "for idx, val in enumerate(col_names):\n",
    "    print ('Kings County:  Price ~ ' + val)\n",
    "    print ('-------------------------------------')\n",
    "    \n",
    "    f = 'price~' + val\n",
    "    model = smf.ols(formula = f, data = kc).fit()\n",
    "    X_new = pd.DataFrame({val: [kc[val].min(), kc[val].max()]});\n",
    "    predic = model.predict(X_new)\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1]])\n",
    "    print (results[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # convert the remaining variables results table to a dataframe\n",
    "print ()\n",
    "print ('OLS with remaining variables')\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal opinion, I sthink that yr_renovated should be removed and possibly basement\n",
    "Date can also be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['date', 'yr_renovated', 'basement_0', 'basement_1']\n",
    "kc = kc.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Validation - using a train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = kc.drop(['price'], axis=1)\n",
    "y = kc['price']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "yhat_train = linreg.predict(X_train)\n",
    "yhat_test = linreg.predict(X_test)\n",
    "\n",
    "# look at the residuals\n",
    "train_residuals = yhat_train - y_train\n",
    "test_residuals = yhat_test - y_test\n",
    "\n",
    "print ('Training Data Residuals: ', train_residuals)\n",
    "print ()\n",
    "print ()\n",
    "print ('Test Data Residuals: ', test_residuals)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squarred error\n",
    "mse_train = np.sum((y_train - yhat_train)**2) / len(y_train)\n",
    "mse_test= np.sum((y_test - yhat_test)**2) / len(y_test)\n",
    "\n",
    "print ('Train Mean Squarred Error: ', mse_train)\n",
    "print ('Test Mean Squarred Error: ', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't think the mse's look good :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
